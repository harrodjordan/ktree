{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custompackage.load_data import *\n",
    "from custompackage.load_architecture import *\n",
    "from custompackage.traintestloop import *\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.optimizer import required\n",
    "from torch.utils.data.dataset import random_split\n",
    "import scipy\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "import pickle\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_fc(model, trainloader, validloader, testloader, epochs=10, patience=60):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    \n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    \n",
    "    loss_curve = []\n",
    "    acc_curve = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "        \n",
    "        \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels, _ = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float().reshape(-1,1))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (torch.round(outputs) == labels.float().reshape(-1,1)).sum().item()/trainloader.batch_size\n",
    "            if i % 4 == 3:    # print every 80 mini-batches\n",
    "                loss_curve.append(running_loss/3)\n",
    "                acc_curve.append(running_acc/3)\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for _, data in enumerate(validloader):\n",
    "            inputs, labels, _ = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(inputs)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, labels.float().reshape(-1,1))\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "                \n",
    "        valid_loss = np.average(valid_losses)\n",
    "\n",
    "\n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    print('Finished Training, %d epochs' % (epoch+1))\n",
    "    \n",
    "    correct = 0\n",
    "    all_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.float().reshape(-1,1))\n",
    "            predicted = torch.round(outputs)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.float().reshape(-1,1)).sum().item()\n",
    "            all_loss += loss\n",
    "    accuracy = correct/total\n",
    "    ave_loss = all_loss.item()/total\n",
    "    \n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * accuracy))\n",
    "        \n",
    "    return(loss_curve, acc_curve, ave_loss, accuracy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 mnist\n",
      "0 6 fmnist\n",
      "2 6 kmnist\n",
      "14 17 emnist\n",
      "5 6 svhn\n",
      "3 5 usps\n",
      "3 5 cifar10\n"
     ]
    }
   ],
   "source": [
    "# Test space for networks\n",
    "# Select Class Set\n",
    "class_set = 3\n",
    "\n",
    "# Initialize settings\n",
    "bs = 256\n",
    "weighting = 'paired'\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "trees_set = [1,2,4,8,16,32]\n",
    "# trees_set = [8]\n",
    "\n",
    "\n",
    "classes = np.load('./results/20200511/classes.npy', allow_pickle=True)\n",
    "\n",
    "# if class_set == 0:\n",
    "#     classes = classes[0:2] # mnist fmnist\n",
    "# elif class_set == 1:\n",
    "#     classes = classes[2:4] # kmnist emnist\n",
    "# elif class_set == 2:\n",
    "#     classes = classes[4:6] # svhn usps\n",
    "# else:\n",
    "#     classes = classes[6].reshape(1,-1)\n",
    "\n",
    "\n",
    "loss = np.zeros((len(classes), trials, len(trees_set)))\n",
    "acc = np.zeros((len(classes), trials, len(trees_set)))\n",
    "\n",
    "    \n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(t1, t2, ds)\n",
    "    trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "    input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "    for i in range(trials):\n",
    "        for k, trees in enumerate(trees_set):\n",
    "            print(j, i, k)\n",
    "#             model = ktree_gen(ds=ds, Repeats=trees, Padded=False).cuda()\n",
    "            model = simple_fcnn(input_size, 2*trees, 1).cuda()\n",
    "            \n",
    "#             loss_curve, acc_curve, loss[j,i,k], acc[j,i,k], model_t = train_test_ktree(model, trainloaders[i],\n",
    "#                                                                                   testloader, epochs = epochs, randorder=False)\n",
    "            loss_curve, acc_curve, loss[j,i], acc[j,i], model_t = train_test_fc(model, trainloaders[i],\n",
    "                                              validloaders[i], testloader, epochs=epochs)\n",
    "\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "    \n",
    "#             np.save('./results/20200504/k_tree_acc_'+str(class_set)+'.npy', acc)\n",
    "#             np.save('./results/20200504/k_tree_loss_'+str(class_set)+'.npy', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00592762]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa7403dd6d8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss[0,0,])\n",
    "plt.plot(loss_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ktree(model, trainloader, validloader, testloader, epochs=10, randorder=False, patience=30):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    loss_curve = []\n",
    "    acc_curve = []\n",
    "    \n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = []\n",
    "    \n",
    "    if randorder == True:\n",
    "        ordering = torch.randperm(len(trainloader.dataset.tensors[0][0]))\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels, _ = data\n",
    "            if randorder == True:\n",
    "                inputs = inputs[:,ordering].cuda()\n",
    "            else:\n",
    "                inputs = inputs.cuda()\n",
    "\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float().reshape(-1,1))\n",
    "            loss.backward()\n",
    "            \n",
    "####        # Freeze select weights by zeroing out gradients\n",
    "            for child in model.children():\n",
    "                for param in child.parameters():\n",
    "                    for freeze_mask in model.freeze_mask_set:\n",
    "                        if param.grad.shape == freeze_mask.shape:\n",
    "                            param.grad[freeze_mask] = 0\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (torch.round(outputs) == labels.float().reshape(-1,1)).sum().item()/trainloader.batch_size\n",
    "            if (i % 4) == 3:    # print every 80 mini-batches\n",
    "                loss_curve.append(running_loss/3)\n",
    "                acc_curve.append(running_acc/3)\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for _, data in enumerate(validloader):\n",
    "            inputs, labels, _ = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(inputs)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, labels.float().reshape(-1,1))\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "                \n",
    "        valid_loss = np.average(valid_losses)\n",
    "\n",
    "\n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    print('Finished Training, %d epochs' % (epoch+1))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, _ = data\n",
    "            if randorder == True:\n",
    "                images = images[:,ordering].cuda()\n",
    "            else:\n",
    "                images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.float().reshape(-1,1))\n",
    "            predicted = torch.round(outputs)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.float().reshape(-1,1)).sum().item()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    \n",
    "    print('Accuracy of the network on the test images: %2f %%' % (\n",
    "        100 * accuracy))\n",
    "    \n",
    "    if randorder == True:\n",
    "        return(loss_curve, acc_curve, loss, accuracy, model, ordering)\n",
    "    else:\n",
    "        return(loss_curve, acc_curve, loss, accuracy, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 mnist\n",
      "0 0 0\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "EarlyStopping counter: 3 out of 30\n",
      "EarlyStopping counter: 4 out of 30\n",
      "EarlyStopping counter: 5 out of 30\n",
      "EarlyStopping counter: 6 out of 30\n",
      "EarlyStopping counter: 7 out of 30\n",
      "EarlyStopping counter: 8 out of 30\n",
      "EarlyStopping counter: 9 out of 30\n",
      "EarlyStopping counter: 10 out of 30\n",
      "EarlyStopping counter: 11 out of 30\n",
      "EarlyStopping counter: 12 out of 30\n",
      "EarlyStopping counter: 13 out of 30\n",
      "EarlyStopping counter: 14 out of 30\n",
      "EarlyStopping counter: 15 out of 30\n",
      "EarlyStopping counter: 16 out of 30\n",
      "EarlyStopping counter: 17 out of 30\n",
      "EarlyStopping counter: 18 out of 30\n",
      "EarlyStopping counter: 19 out of 30\n",
      "EarlyStopping counter: 20 out of 30\n",
      "EarlyStopping counter: 21 out of 30\n",
      "EarlyStopping counter: 22 out of 30\n",
      "EarlyStopping counter: 23 out of 30\n",
      "EarlyStopping counter: 24 out of 30\n",
      "EarlyStopping counter: 25 out of 30\n",
      "EarlyStopping counter: 26 out of 30\n",
      "EarlyStopping counter: 27 out of 30\n",
      "EarlyStopping counter: 28 out of 30\n",
      "EarlyStopping counter: 29 out of 30\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping\n",
      "Finished Training, 1128 epochs\n",
      "Accuracy of the network on the test images: 96.477392 %\n"
     ]
    }
   ],
   "source": [
    "# Test space for networks\n",
    "# Select Class Set\n",
    "class_set = 0\n",
    "\n",
    "# Initialize settings\n",
    "bs = 256\n",
    "weighting = 'paired'\n",
    "trials = 10\n",
    "epochs = 2000\n",
    "# trees_set = [1,2,4,8,16,32]\n",
    "trees_set = [8]\n",
    "\n",
    "\n",
    "classes = np.load('./results/20200511/classes.npy', allow_pickle=True)\n",
    "\n",
    "if class_set == 0:\n",
    "    classes = classes[0:2] # mnist fmnist\n",
    "elif class_set == 1:\n",
    "    classes = classes[2:4] # kmnist emnist\n",
    "elif class_set == 2:\n",
    "    classes = classes[4:6] # svhn usps\n",
    "else:\n",
    "    classes = classes[6].reshape(1,-1)\n",
    "\n",
    "\n",
    "loss = np.zeros((len(classes), trials, len(trees_set)))\n",
    "acc = np.zeros((len(classes), trials, len(trees_set)))\n",
    "\n",
    "    \n",
    "for j, (t1, t2, ds) in enumerate(classes):\n",
    "    print(t1, t2, ds)\n",
    "    trainloaders, validloaders, testloader = dataset_weighted_split_all(bs, t1, t2, weighting, trials, ds, permute=False)\n",
    "    input_size = trainloaders[0].dataset.tensors[0][0].shape[0]\n",
    "    for i in range(trials):\n",
    "        for k, trees in enumerate(trees_set):\n",
    "            print(j, i, k)\n",
    "            model = ktree_gen(ds=ds, Repeats=trees, Padded=True).cuda()\n",
    "#             model = simple_fcnn(input_size, 2*trees, 1).cuda()\n",
    "            \n",
    "            loss_curve, acc_curve, loss[j,i,k], acc[j,i,k], model_t = train_test_ktree(model, trainloaders[i],\n",
    "                                                                                  validloaders[i], testloader, epochs = epochs, randorder=False)\n",
    "#             loss_curve, acc_curve, loss[j,i], acc[j,i], model_t = train_test_fc(model, trainloaders[i],\n",
    "#                                               validloaders[i], testloader, epochs = epochs)\n",
    "\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "    \n",
    "#             np.save('./results/20200504/k_tree_acc_'+str(class_set)+'.npy', acc)\n",
    "#             np.save('./results/20200504/k_tree_loss_'+str(class_set)+'.npy', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
